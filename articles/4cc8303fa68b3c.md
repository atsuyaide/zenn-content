---
title: "Dockerを活用してKafkaクラスターを複数マシン上で構築し, 各種UIツールを試す"
emoji: "⛳"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Kafka", "Python"]
published: false
---

# はじめに

マイクロサービスの勉強中に, [Apache Kafka](https://kafka.apache.org/)という技術が存在することを知りました.
Kafka の勉強がてら Docker を活用して構築する手順をまとめたので記事にまとめます.

## 🖨 この記事で取り扱うこと

Kafka の基本的な概念や用語については説明しません. あくまで手を動かしながら

- Docker を活用してローカル環境に Kafka クラスターを構築する
- Kafka の状態を監視/操作する UI ツールを試す
- クライアントアプリケーション(Python)を動作させる

ことに焦点を当てます.

なお, Kafka クラスターは複数マシン(それぞれが別 IP アドレスを持つ)上で構成します.
とはいっても, 自宅に複数台のマシンがあるのは逸般のご家庭くらいですし, クラウド環境で手配するのも面倒です. この記事では, Docker を活用しローカル環境に複数のコンテナを起動させ, 仮想的に複数台のマシンがある環境を再現します.

## 😎 注意事項

実際に手を動かしながら進めたい方は, 以下の環境/知識が必要です.

- [x] 環境: Docker および Docker Compose V2 が利用できる環境
- [x] 知識: Docker の基本コマンドを使えること

なお, できるだけシンプルな Kafka のハンズオンを目指したためセキュリティ的な設定は割愛しています. 商用環境で動作させる場合やセキュリティを重視する場合は適宜設定をお願いします.

## 📡 全体構成

![全体構成図](https://github.com/atsuyaide/kafka-training/blob/main/blob/overall.dio.png?raw=true)

Windows 10 上の WSL2(Ubuntu 22.04)内で Docker を利用して複数のコンテナを立ち上げています. それぞれのコンテナは異なる IP アドレスを持っており, コンテナ内部で Kafka, Zookeeper, 各種 UI を dind(Docker in Docker)で構築します.

あくまで WSL2 直上のコンテナは別 IP アドレスを持つマシンを仮想的に構築するために利用しています.

## 🎯 準備

[ソースコード](https://github.com/atsuyaide/kafka-training.git)をクローンし, フォルダ内に入ります.

```shell
git clone https://github.com/atsuyaide/kafka-training.git
cd kafka-training
```

コンテナを起動し, ローカルに複数マシンのある環境を仮想的に構築します.

```shell
docker compose up -d
```

各コンテナの IP アドレスを確認します. 下記のコマンドで実行中のコンテナの IP アドレスを表示できます.

```shell
$ docker ps -q | xargs -n 1 docker inspect --format '{{ .Name }} {{range .NetworkSettings.Networks}} {{.IPAddress}}{{end}}' | sed 's#^/##' | sort -k 2
broker-1  172.19.0.2
broker-2  172.19.0.3
broker-3  172.19.0.4
kafka-ui  172.19.0.5
producer  172.19.0.6
consumer  172.19.0.7
```

表示される IP アドレスは環境によって異なります. ほかのコンテナを既に起動していたり, `docker0` の設定変更をしている場合は IP が異なるはずです.

表示された IP アドレスを各コンテナにマウントされている`.env`ファイルに書き込みます.
`broker-1`, `2`, `3` の IP アドレスを`kafka`, `client`ディレクトリ配下の`.env`ファイルに反映します. `.env`ファイルのテンプレートとして`.env.template`が用意しているので, 同じディレクトリにコピーしてファイルを編集してください.

私の環境ではそれぞれの`.env`ファイルを以下のように設定することとなります.

```shell
BROKER1=172.19.0.2
BROKER2=172.19.0.3
BROKER3=172.19.0.4
```

これで準備完了です.
現時点で以下のディレクトリとファイル構成になっているはずです.

```shell
$ tree -a ./kafka
kafka
├── broker-1
│   ├── .env
│   ├── .env.template
│   ├── compose.kafka.yml
│   └── compose.zookeeper.yml
├── broker-2
│   ├── .env
│   ├── .env.template
│   ├── compose.kafka.yml
│   └── compose.zookeeper.yml
├── broker-3
│   ├── .env
│   ├── .env.template
│   ├── compose.kafka.yml
│   └── compose.zookeeper.yml
└── ui
    ├── .env
    ├── .env.template
    ├── compose.cmak.yml
            ...
    └── compose.ui.yml
```

```shell
$ tree -a ./kafka
├── consumer
│   ├── .env
│   ├── .env.template
│   ├── main.py
│   └── requirements.txt
└── producer
    ├── .env
    ├── .env.template
    ├── main.py
    └── requirements.txt
```

## 🌊 Kafka クラスターを構築

Apache Kafka は Apache Zookeeper と接続する必要があります.
まず, Zookeeper クラスターを構成した後, 各ホストで Kafka を起動してクラスターを構成します. また, 以降の作業は複数のターミナルでの作業をおすすめします. 必要に応じて tmux やターミナルの split 機能を活用してください.

### Zookeeper クラスターの構成

Zookeeper を `broker-1`, `2`, `3`で起動し, クラスターを構成します. 起動順序は特に指定はありませんが, ここでは ID 順に起動していきます.

コンテナに入ります.

```shell
docker exec -it broker-1 sh
```

Zookeeper を起動します.

```shell
docker compose -f ./src/compose.zookeeper.yml up -d
```

この作業を`broker-1`, `2`, `3`の各コンテナでも実行してください.

全ての Zookeeper を起動後, ログを確認しながら Zookeeper が正常に起動できているか確認します. `broker-1`で`zookeeper-1`のログを確認したい場合, `broker-1`内で下記のコマンドを実行します.

```shell
docker logs zookeeper-1
```

エラーが発生している場合は内容に応じて適宜対応してください. 正常にクラスターを組めた場合は`LEADER`/`FOLLOWER`の割り当て完了のログなどが表示されます.

### Kafak を起動

Kafka を `broker-1`, `2`, `3`で起動し, クラスターを構成します.
起動時に Zookeeper クラスターに接続しますが, Kafka も起動順序について特に指定はありません.
ここでも ID 順に起動していきます.

Kafka を起動します.

```shell
docker compose -f ./src/compose.kafka.yml up -d
```

この作業を`broker-1`, `2`, `3`の各コンテナでも実行してください.

全ての Kafka が正常に起動できているか確認してください. 要領は Zookeeper と同じです.

## 🕶 各種 UI ツールを試す

GitHub の[kafka-ui](https://github.com/topics/kafka-ui)のタグがついており, スター数の多いものを試します. このセクションでは様々な UI ツールを試す環境を提供しますが, 詳細は説明しません(記事が長くなりますし, まとめるのが大変なので).

UI 起動用のコンテナに入ります.

```shell
docker exec -it kafka-ui sh
```

下記の中から利用したい UI ツールを起動してくだい.

### [Kafka Topics UI](https://github.com/lensesio/kafka-topics-ui)

```shell
docker compose -f ./src/compose.topics-ui.yml up -d
```

`localhost:8000`にアクセスすると UI が表示されます.

![Kafka Topics UIのトップ画面](https://github.com/atsuyaide/kafka-training/blob/main/blob/kafka-topics-ui.png?raw=true)

一番シンプル. メッセージは確認できるが, トピックの作成などはできない.

### [Redpanda Console](https://github.com/redpanda-data/console)

```shell
docker compose -f ./src/compose.redpanda-console.yml up -d
```

`localhost:8080`にアクセスすると UI が表示されます.

![Redpanda Consoleのトップ画面](https://github.com/atsuyaide/kafka-training/blob/main/blob/redpanda-console.png?raw=true)

### [Kafka UI](https://github.com/provectus/kafka-ui)

```shell
docker compose -f ./src/compose.ui.yml up -d
```

`localhost:8888`アクセスすると UI が表示されます.

![Kafka UIのトップ画面](https://github.com/atsuyaide/kafka-training/blob/main/blob/kafka-ui.png?raw=true)

個人的には一番使いやすいと感じました. 機能も最も充実している気がします.

### [CMAK](https://github.com/yahoo/CMAK)(Kafka Manager の後継)

```shell
docker compose -f ./src/compose.cmak.yml up -d
```

`localhost:9000`にアクセスすると UI が表示されます.

![CMAKのトップ画面](https://github.com/atsuyaide/kafka-training/blob/main/blob/cmak.png?raw=true)

> NOTE クラスターの追加は手動または[API](https://github.com/yahoo/CMAK/blob/master/conf/routes)で実行する必要があります. 起動時に指定する`ZK_HOSTS`は CMAK を監視するための Zookeeper であって, Kafka クラスターではないため.

### [Kafdrop](https://github.com/obsidiandynamics/kafdrop)

```shell
docker compose -f ./src/compose.kafdrop.yml up -d
```

`localhost:9090`にアクセスすると UI が表示されます.

![Kafdropのトップ画面](https://github.com/atsuyaide/kafka-training/blob/main/blob/kafdrop.png?raw=true)

## 🎮 クライアント API を試す

[kafka-python](https://kafka-python.readthedocs.io/en/master/)を使って実際にメッセージを流してみます.

![Pythonクライアントを使ったデモ](https://github.com/atsuyaide/kafka-training/blob/main/blob/demo.gif?raw=true)

左がプロデューサー, 右がコンシューマーです.
プロデューサーが送信した文字列をコンシューマーが即時受け取れていることを確認できます.

### プロデューサー側

プロデューサー側のコンテナに入ります.

```shell
docker exec -it producer sh
```

ライブラリをインストールします.

```shell
pip install -r /src/requirements.txt
```

Producer を起動します. `--bootstrap-servers`の部分は自身の情報で実行してください.

```shell
python /src/main.py --topic sample-topic --bootstrap-servers 172.19.0.2:9092,172.19.0.3:9092,172.19.0.4:9092
```

文字列を入力し, Enter で Kafka クラスターにメッセージを送信できます.

### コンシューマー側

コンシューマー側のコンテナに入ります.

```shell
docker exec -it consumer sh
```

ライブラリをインストールします.

```shell
pip install -r /src/requirements.txt
```

Producer を起動します. `--bootstrap-servers`の部分は自身の情報で実行してください.

```shell
python /src/main.py --topic sample-topic --bootstrap-servers 172.19.0.2:9092,172.19.0.3:9092,172.19.0.4:9092
```

起動すると待ち受け状態に入り, 到着したメッセージ標準出力されます.

また, [各種 UI ツールを試す](#各種-ui-ツールを試す)のセクションで起動した一部のツールでは, 到着したメッセージを確認できます. また, `--group-id`でコンシューマーグループ ID を指定できます. 指定して実行すると UI ツールのコンシューマ一覧に表示されるようになります.

![Kafka UIのConsumers画面](https://github.com/atsuyaide/kafka-training/blob/main/blob/consumers.png?raw=true)

この画像は`--group-id sample-group`とした場合です.

## 🎉 おわりに

全てのコンテナを落として終了です.

```shell
docker compose down
```

お疲れ様でした!!
